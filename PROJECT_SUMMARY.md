# Proje Ã–zeti

Common Crawl'dan Next.js kullanan web sitelerini tespit eden profesyonel crawler sistemi.

## ğŸ¯ Proje Hedefi

**100,000 WARC dosyasÄ±nÄ± tara â†’ Next.js kullanan tÃ¼m siteleri bul (subdomain dahil tÃ¼m TLD'ler)**

## ğŸš€ Temel Ã–zellikler

### 1. Verimli Veri Ã‡ekme
- âœ… HTTP Range requests (sadece gerekli kÄ±smÄ± indir)
- âœ… ~%99.9 bant geniÅŸliÄŸi tasarrufu
- âœ… 1GB WARC yerine 10MB sample

### 2. AkÄ±llÄ± Next.js Tespiti
- âœ… `__NEXT_DATA__` script tag
- âœ… `/_next/static/` path'leri
- âœ… Build ID extraction
- âœ… Meta tag analizi
- âœ… 3 seviye gÃ¼ven skoru (high/medium/low)

### 3. GeliÅŸmiÅŸ Retry Sistemi â­ YENÄ°
- âœ… 5 deneme hakkÄ±
- âœ… Her baÅŸarÄ±sÄ±zlÄ±kta 5 dakika bekleme
- âœ… BaÅŸarÄ±sÄ±z WARC'larÄ± kaydetme
- âœ… Resume desteÄŸi (kaldÄ±ÄŸÄ± yerden devam)
- âœ… DetaylÄ± failure raporlama

### 4. Rate Limiting & Ban Prevention
- âœ… Token bucket algorithm
- âœ… Adaptive rate limiter
- âœ… Common Crawl friendly

### 5. Paralel Ä°ÅŸleme
- âœ… ThreadPoolExecutor ile paralel WARC iÅŸleme
- âœ… Configurable worker count
- âœ… Progress tracking

### 6. Tam Coverage
- âœ… TÃ¼m TLD'ler (.com, .org, .io, .dev, .xyz, vb.)
- âœ… Subdomain'ler (blog.example.com, api.test.io)
- âœ… Country TLD'ler (.co.uk, .com.tr, .de)

## ğŸ“ Proje YapÄ±sÄ±

```
CrawData/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cdx/                    # CDX API client
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ client.py
â”‚   â”œâ”€â”€ warc/                   # WARC fetcher & parser
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ fetcher.py         # HTTP Range ile segment Ã§ekme
â”‚   â”‚   â””â”€â”€ parser.py          # WARC parse & HTML extraction
â”‚   â”œâ”€â”€ detectors/              # Next.js detection
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ nextjs.py          # Pattern matching & confidence scoring
â”‚   â”œâ”€â”€ utils/                  # Utilities
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ rate_limiter.py    # Rate limiting
â”‚   â”‚   â”œâ”€â”€ logger.py          # Logging
â”‚   â”‚   â””â”€â”€ retry_handler.py   # â­ Retry & failure tracking
â”‚   â”œâ”€â”€ crawler.py              # Main crawler orchestrator
â”‚   â””â”€â”€ warc_processor.py       # â­ Advanced WARC processor
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ simple_search.py        # Basit CDX arama
â”‚   â”œâ”€â”€ specific_domains.py     # Belirli domainleri kontrol
â”‚   â”œâ”€â”€ bulk_warc_search.py     # Toplu WARC tarama
â”‚   â”œâ”€â”€ find_all_nextjs.py      # TÃ¼m TLD'leri tara
â”‚   â””â”€â”€ test_components.py      # Component testleri
â”‚
â”œâ”€â”€ main.py                     # CDX-based ana script
â”œâ”€â”€ process_warcs.py            # â­ WARC processor ana script (ADVANCED)
â”œâ”€â”€ warc.paths                  # 100,000 WARC dosya listesi
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ output/                 # SonuÃ§lar (JSON + CSV)
â”‚   â””â”€â”€ failures/               # â­ BaÅŸarÄ±sÄ±z WARC'lar
â”‚
â”œâ”€â”€ logs/                       # Log dosyalarÄ±
â”‚
â”œâ”€â”€ README.md                   # Ana dokÃ¼mantasyon
â”œâ”€â”€ QUICKSTART.md              # HÄ±zlÄ± baÅŸlangÄ±Ã§
â”œâ”€â”€ COMPARISON.md              # YÃ¶ntem karÅŸÄ±laÅŸtÄ±rmasÄ±
â”œâ”€â”€ ARCHITECTURE.md            # Mimari detaylarÄ±
â”œâ”€â”€ RETRY_SYSTEM.md            # â­ Retry sistemi dokÃ¼mantasyonu
â”œâ”€â”€ requirements.txt           # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ Makefile                   # Kolay komutlar
â””â”€â”€ .gitignore
```

## ğŸ® KullanÄ±m

### HÄ±zlÄ± BaÅŸlangÄ±Ã§

```bash
# 1. Kurulum
make install

# 2. Test (10 WARC)
make process-test

# 3. KÃ¼Ã§Ã¼k Ã¶lÃ§ek (100 WARC)
make process-small

# 4. BÃ¼yÃ¼k Ã¶lÃ§ek (1000 WARC)
make process-large

# 5. BaÅŸarÄ±sÄ±zlarÄ± retry
make resume
```

### DetaylÄ± KullanÄ±m

```bash
# Ã–zel parametrelerle
python process_warcs.py \
  --limit 500 \
  --workers 10 \
  --retry-delay 300 \
  --max-retries 5 \
  --sample-size 10

# Ã–nceki baÅŸarÄ±sÄ±zlÄ±klarÄ± retry
python process_warcs.py \
  --resume-from data/failures/failed_warcs_20240115.json
```

## ğŸ“Š Ã‡Ä±ktÄ± FormatÄ±

### JSON
```json
[
  {
    "domain": "blog.example.com",
    "url": "https://blog.example.com/page",
    "confidence": "high",
    "indicators": ["__NEXT_DATA__", "/_next/static/"],
    "build_id": "abc123xyz",
    "warc_source": "crawl-data/CC-MAIN-2025-47/..."
  }
]
```

### CSV
```csv
domain,url,confidence,build_id,warc_source
blog.example.com,https://blog.example.com,high,abc123xyz,crawl-data/...
api.test.io,https://api.test.io,medium,,crawl-data/...
```

### Failure JSON
```json
{
  "session_id": "20240115_103000",
  "total_failures": 15,
  "failures": [
    {
      "warc_path": "crawl-data/...",
      "failure_reason": "timeout",
      "failure_count": 5,
      "error_message": "ReadTimeout..."
    }
  ]
}
```

## ğŸ”„ Workflow

### Tam Pipeline

```
1. Ä°lk Ã§alÄ±ÅŸtÄ±rma (1000 WARC)
   â”œâ”€> 950 baÅŸarÄ±lÄ±
   â”œâ”€> 50 baÅŸarÄ±sÄ±z (saved)
   â””â”€> ~300 Next.js sitesi bulundu

2. Resume (50 baÅŸarÄ±sÄ±z WARC)
   â”œâ”€> 40 baÅŸarÄ±lÄ±
   â”œâ”€> 10 hala baÅŸarÄ±sÄ±z
   â””â”€> ~12 Next.js sitesi daha bulundu

3. Son retry (10 WARC)
   â”œâ”€> 8 baÅŸarÄ±lÄ±
   â”œâ”€> 2 kalÄ±cÄ± baÅŸarÄ±sÄ±z
   â””â”€> ~2 Next.js sitesi daha bulundu

Toplam: ~314 Next.js sitesi âœ…
```

## ğŸ¯ Performans

### HÄ±z
- **10 WARC:** ~5-10 dakika
- **100 WARC:** ~1-2 saat
- **1,000 WARC:** ~10-20 saat
- **10,000 WARC:** ~4-8 gÃ¼n
- **100,000 WARC:** ~40-80 gÃ¼n (1-3 ay)

### Beklenen SonuÃ§lar
- **1,000 WARC:** ~200-500 Next.js sitesi
- **10,000 WARC:** ~2,000-5,000 Next.js sitesi
- **100,000 WARC:** ~20,000-50,000 Next.js sitesi

### Kaynak KullanÄ±mÄ±
- **Memory:** ~500MB-1GB (5-10 worker)
- **Disk:** ~100MB-1GB (sonuÃ§lar)
- **Network:** ~10-50 Mbps sustained
- **CPU:** Moderate (parsing)

## ğŸ›¡ï¸ GÃ¼venlik & Best Practices

### Rate Limiting
```python
# Default: 2 req/s (gÃ¼venli)
rate_limit = 2.0

# Aggressive: 5-10 req/s (riskli)
# Conservative: 0.5-1 req/s (Ã§ok yavaÅŸ)
```

### Retry Strategy
```python
# Default: 5 deneme, 5 dakika bekleme
max_retries = 5
retry_delay = 300  # seconds

# HÄ±zlÄ± test: 3 deneme, 1 dakika
# GÃ¼venli: 10 deneme, 10 dakika
```

### Worker Count
```python
# BaÅŸlangÄ±Ã§: 3-5 workers
# Normal: 5-10 workers
# Aggressive: 10-20 workers (riskli)
```

## ğŸ“ˆ Ä°zleme & Raporlama

### Real-time Output
```bash
Processing WARCs: 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 450/1000 [02:15<02:45,  3.32it/s]

âœ“ Found: blog.example.com (high)
âœ“ Found: api.test.io (medium)
âœ“ Found: shop.demo.org (high)
```

### Final Report
```
============================================================
FINAL STATISTICS
============================================================
Total processed: 1000
Successful: 950
Failed: 50
Next.js sites found: 314
Unique domains: 298

Failure breakdown:
  timeout: 30
  connection_error: 15
  http_error: 5
============================================================
```

## ğŸ”§ Troubleshooting

### Ã‡ok Fazla Timeout
```bash
# Daha uzun timeout, daha az worker
--retry-delay 600 --workers 3
```

### Memory HatasÄ±
```bash
# Daha kÃ¼Ã§Ã¼k sample, daha az worker
--sample-size 5 --workers 2
```

### Ban/Rate Limit
```bash
# Daha yavaÅŸ rate limit
--rate-limit 1.0 --retry-delay 600
```

## ğŸ“š DokÃ¼mantasyon

- **README.md**: Genel bakÄ±ÅŸ
- **QUICKSTART.md**: HÄ±zlÄ± baÅŸlangÄ±Ã§ rehberi
- **COMPARISON.md**: YÃ¶ntem karÅŸÄ±laÅŸtÄ±rmasÄ±
- **ARCHITECTURE.md**: Teknik mimari
- **RETRY_SYSTEM.md**: Retry sistemi detaylarÄ±

## ğŸ“ Ã–rnekler

### 1. Test Ã‡alÄ±ÅŸtÄ±rmasÄ±
```bash
make process-test
# 10 WARC, ~5 dakika, ~5-10 site
```

### 2. KÃ¼Ã§Ã¼k AraÅŸtÄ±rma
```bash
make process-small
# 100 WARC, ~2 saat, ~50-100 site
```

### 3. Ciddi Tarama
```bash
make process-large
# 1000 WARC, ~20 saat, ~300-500 site
```

### 4. Full Tarama (Uzun Vadeli)
```bash
# Split into batches
for i in {1..10}; do
  python process_warcs.py --limit 10000 --workers 10
  make resume
  sleep 3600  # 1 saat ara
done
```

## ğŸŒŸ GeliÅŸmiÅŸ Ã–zellikler

### 1. Adaptive Rate Limiting
```python
from src.utils import AdaptiveRateLimiter

# Otomatik rate ayarlama
# Success â†’ rate artÄ±r
# Error â†’ rate azalt
```

### 2. Failure Analysis
```python
from src.utils import FailureTracker

tracker = FailureTracker()
stats = tracker.get_statistics()
# {'timeout': 30, 'connection_error': 15, ...}
```

### 3. Resume System
```bash
# Otomatik en son failure'Ä± bul ve retry et
make resume

# Manuel belirli failure file
python process_warcs.py --resume-from data/failures/failed_warcs_X.json
```

## ğŸ¯ SonuÃ§

Bu proje, Common Crawl'Ä±n 100,000 WARC dosyasÄ±ndan Next.js kullanan siteleri verimli, gÃ¼venli ve Ã¶lÃ§eklenebilir bir ÅŸekilde bulur.

**Temel Avantajlar:**
- âœ… HTTP Range ile %99.9 veri tasarrufu
- âœ… 5 deneme + 5 dakika bekleme ile yÃ¼ksek baÅŸarÄ± oranÄ±
- âœ… Failure tracking ile hiÃ§bir veri kaybÄ± yok
- âœ… Resume desteÄŸi ile kesintisiz iÅŸlem
- âœ… TÃ¼m TLD ve subdomain'leri kapsar
- âœ… Paralel iÅŸlem ile hÄ±zlÄ± tarama

**KullanÄ±m SenaryolarÄ±:**
1. Next.js market araÅŸtÄ±rmasÄ±
2. Akademik Ã§alÄ±ÅŸmalar
3. SEO analizi
4. Framework adoption trends
5. Web teknoloji analizi

**Ä°letiÅŸim & KatkÄ±:**
- Issues: GitHub issues
- KatkÄ±da bulunmak iÃ§in pull request gÃ¶nderin
- DokÃ¼mantasyon iyileÅŸtirmeleri hoÅŸ karÅŸÄ±lanÄ±r

---

Made with â¤ï¸ for the Next.js community
